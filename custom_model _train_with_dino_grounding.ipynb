{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWCh8ki339sex0W9gUDv+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AprendeIngenia/Auto-Labeling-with-Grounding-DINO/blob/main/custom_model%20_train_with_dino_grounding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeling with Grounding DINO"
      ],
      "metadata": {
        "id": "TbGKc_5sQ_sL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check GPU"
      ],
      "metadata": {
        "id": "EOqKyhUWRD-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crSO_o5_Qt_G"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "VmnIL6aFRG_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content"
      ],
      "metadata": {
        "id": "kPCBry9aRIa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()"
      ],
      "metadata": {
        "id": "TCjRgBddRLkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and install Grounding DINO"
      ],
      "metadata": {
        "id": "ESCjiehURNDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git"
      ],
      "metadata": {
        "id": "zCbV74pTROg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/GroundingDINO\n",
        "!pip install -q -e .\n",
        "!pip install supervision"
      ],
      "metadata": {
        "id": "wN20MIr2RP_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download weights"
      ],
      "metadata": {
        "id": "WhkSi8miRRIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth"
      ],
      "metadata": {
        "id": "RTCNpPQ0RTWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/GroundingDINO"
      ],
      "metadata": {
        "id": "T2qxkd0MRU7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object detect with Grounding DINO"
      ],
      "metadata": {
        "id": "QYjzehT9RWVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load weights"
      ],
      "metadata": {
        "id": "jRSLhvVRRbbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/GroundingDINO\n",
        "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
        "\n",
        "model = load_model(f\"{HOME}/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\",\n",
        "                   f\"{HOME}/weights/groundingdino_swint_ogc.pth\")"
      ],
      "metadata": {
        "id": "iFX6MTdKRc0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Detect"
      ],
      "metadata": {
        "id": "hcqPRFa7Rd_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import supervision as sv\n",
        "\n",
        "IMAGE_NAME = \"/content/data/images/wrench_100.jpg\"\n",
        "IMAGE_PATH = os.path.join(HOME, 'data', IMAGE_NAME)\n",
        "\n",
        "TEXT_PROMPT = \"wrench\"\n",
        "BOX_THRESHOLD = 0.7\n",
        "TEXT_THRESHOLD = 0.25\n",
        "\n",
        "image_source, image = load_image(IMAGE_NAME)\n",
        "\n",
        "boxes, logits, phrases = predict(\n",
        "    model = model,\n",
        "    image = image,\n",
        "    caption = TEXT_PROMPT,\n",
        "    box_threshold = BOX_THRESHOLD,\n",
        "    text_threshold = TEXT_THRESHOLD,\n",
        "    device = 'cuda'\n",
        "    )\n",
        "\n",
        "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(annotated_frame, (16,16))"
      ],
      "metadata": {
        "id": "w7Ffr34fRfsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labeling with Grounding DINO"
      ],
      "metadata": {
        "id": "HLzD_jysRg6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!find /content/data/images -type d -name \".ipynb_checkpoints\" -exec rm -r {} +"
      ],
      "metadata": {
        "id": "hNrfZGaNRicA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import os\n",
        "from time import time\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from GroundingDINO.groundingdino.util.inference import load_model, predict, annotate\n",
        "import GroundingDINO.groundingdino.datasets.transforms as T"
      ],
      "metadata": {
        "id": "-3isd4ETRjsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def read_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    clases = []\n",
        "    lista = os.listdir(folder_path)\n",
        "\n",
        "    for lis in lista:\n",
        "        img_path = os.path.join(folder_path, lis)\n",
        "        img = cv2.imread(img_path)\n",
        "        images.append(img)\n",
        "        clases.append(os.path.splitext(lis)[0])\n",
        "\n",
        "    return images, clases\n",
        "\n",
        "def save_results(image, boxes, class_id, out_folder):\n",
        "    # Norm\n",
        "    xc, yc, an, al = boxes[0][0], boxes[0][1], boxes[0][2], boxes[0][3]\n",
        "\n",
        "    xc, yc, an, al = max(0, min(1, xc)), max(0, min(1, yc)), max(0, min(1, an)), max(0, min(1, al))\n",
        "\n",
        "    list_info = [f\"{class_id} {xc} {yc} {an} {al}\"]\n",
        "\n",
        "    time_now = str(time()).replace('.', '')\n",
        "\n",
        "    cv2.imwrite(f\"{out_folder}/{time_now}.jpg\", image)\n",
        "\n",
        "    for info in list_info:\n",
        "        with open(f\"{out_folder}/{time_now}.txt\", 'a') as f:\n",
        "            f.write(info)\n",
        "\n",
        "def main():\n",
        "    img_folder_path = '/content/data/images'\n",
        "    out_folder_path = '/content/data/annotations'\n",
        "    class_id = 1\n",
        "    save_results_flag = True\n",
        "\n",
        "    images, classes = read_images_from_folder(img_folder_path)\n",
        "    num_images = len(images)\n",
        "\n",
        "    print(f\"Imagenes: {num_images}\")\n",
        "    print(f'Nombres: {classes}')\n",
        "\n",
        "    home = os.getcwd()\n",
        "\n",
        "    # Config Path\n",
        "    config_path = os.path.join(home, \"/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
        "\n",
        "    # CheckPoint Weights\n",
        "    check_point_path = '/content/weights/groundingdino_swint_ogc.pth'\n",
        "\n",
        "    # Model\n",
        "    model = load_model(config_path, check_point_path)\n",
        "\n",
        "    # Prompt\n",
        "    text_prompt = 'flexometer'\n",
        "    box_threshold = 0.40\n",
        "    text_threshold = 0.25\n",
        "\n",
        "    for con in range(num_images):\n",
        "        img = images[con]\n",
        "        print(\"------------------//--------------------\")\n",
        "        print(f\"Image: {classes[con]}\")\n",
        "\n",
        "        img_copy = img.copy()\n",
        "\n",
        "        transform = T.Compose([\n",
        "            T.RandomResize([800], max_size=1333),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        img_source = Image.fromarray(img).convert(\"RGB\")\n",
        "        img_transform, _ = transform(img_source, None)\n",
        "\n",
        "        boxes, logits, phrases = predict(\n",
        "            model=model,\n",
        "            image=img_transform,\n",
        "            caption=text_prompt,\n",
        "            box_threshold=box_threshold,\n",
        "            text_threshold=text_threshold,\n",
        "            device=DEVICE)\n",
        "\n",
        "        if len(boxes) != 0:\n",
        "            if save_results_flag:\n",
        "                save_results(img_copy, boxes, class_id, out_folder_path)\n",
        "\n",
        "        annotated_img = annotate(image_source=img, boxes=boxes, logits=logits, phrases=phrases)\n",
        "        out_frame = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "mvTqL6fMRmGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compress annotations"
      ],
      "metadata": {
        "id": "CbRL-1wERm0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/content/data/annotations.zip\" \"/content/data/annotations\""
      ],
      "metadata": {
        "id": "wJR7jxUwRoF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete old images"
      ],
      "metadata": {
        "id": "fmBenYzgRqGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import rmtree\n",
        "rmtree(\"/content/dataTrain/train/images\")"
      ],
      "metadata": {
        "id": "6dGzCrRbRrXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Yolo v8 Model"
      ],
      "metadata": {
        "id": "7BNo77MpRsh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "PQ581j3XRuDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/models"
      ],
      "metadata": {
        "id": "JSfoivLiRvfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt"
      ],
      "metadata": {
        "id": "nwgbJtgyRwt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train custom model"
      ],
      "metadata": {
        "id": "yJJGZeynRx_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "id": "3DY_jE4gRzO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Model\n",
        "model = YOLO('/content/models/yolov8n.pt')\n",
        "\n",
        "def main():\n",
        "    #Train\n",
        "    model.train(data='/content/dataTrain/data.yaml', epochs = 40, batch = 64, imgsz = 640, device = 'cuda')\n",
        "\n",
        "if __name__ == 'main':\n",
        "    main()"
      ],
      "metadata": {
        "id": "tiiREq8RR1Kz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
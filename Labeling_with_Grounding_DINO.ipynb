{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true,
      "authorship_tag": "ABX9TyPUuWwRx/H+lHLnh7mYhZU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AprendeIngenia/Auto-Labeling-with-Grounding-DINO/blob/main/Labeling_with_Grounding_DINO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeling with Grounding DINO"
      ],
      "metadata": {
        "id": "eHkXJUPABRnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check GPU"
      ],
      "metadata": {
        "id": "v6Tb6-zIBVno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw0RfN6zBNhQ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "XSGa7zinBhFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQB1piUiBisy",
        "outputId": "7e6df561-3cee-4ac2-f242-3bec6ca670c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()"
      ],
      "metadata": {
        "id": "inHQILWLBlri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and install Grounding DINO"
      ],
      "metadata": {
        "id": "VAnFF9GTBugc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git"
      ],
      "metadata": {
        "id": "JGIePS5YC19t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/GroundingDINO\n",
        "!pip install -q -e .\n",
        "!pip install supervision"
      ],
      "metadata": {
        "id": "z2nhz6PhDOgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download weights"
      ],
      "metadata": {
        "id": "rbOjrUTaD3o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth"
      ],
      "metadata": {
        "id": "ZZeHlMaiD9WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/GroundingDINO"
      ],
      "metadata": {
        "id": "zOD7tDfAETrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object detect with Grounding DINO"
      ],
      "metadata": {
        "id": "mQTDW6jlEjCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load weights"
      ],
      "metadata": {
        "id": "cAQlmgjeEnBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/GroundingDINO\n",
        "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
        "\n",
        "model = load_model(f\"{HOME}/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\",\n",
        "                   f\"{HOME}/weights/groundingdino_swint_ogc.pth\")"
      ],
      "metadata": {
        "id": "llywP_ipEmAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Detect"
      ],
      "metadata": {
        "id": "fGXsE-U2Fr-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import supervision as sv\n",
        "\n",
        "IMAGE_NAME = \"/content/data/images/0.jpg\"\n",
        "IMAGE_PATH = os.path.join(HOME, 'data', IMAGE_NAME)\n",
        "\n",
        "TEXT_PROMPT = \"watch and bill bank\"\n",
        "BOX_THRESHOLD = 0.45\n",
        "TEXT_THRESHOLD = 0.25\n",
        "\n",
        "image_source, image = load_image(IMAGE_NAME)\n",
        "\n",
        "boxes, logits, phrases = predict(\n",
        "    model = model,\n",
        "    image = image,\n",
        "    caption = TEXT_PROMPT,\n",
        "    box_threshold = BOX_THRESHOLD,\n",
        "    text_threshold = TEXT_THRESHOLD,\n",
        "    device = 'cuda'\n",
        "    )\n",
        "\n",
        "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(annotated_frame, (16,16))"
      ],
      "metadata": {
        "id": "xXtgaicTFtTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labeling with Grounding DINO"
      ],
      "metadata": {
        "id": "tkKkWFmQIL8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!find /content/data/images -type d -name \".ipynb_checkpoints\" -exec rm -r {} +"
      ],
      "metadata": {
        "id": "f5fA2SVkIN9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import os\n",
        "from time import time\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from GroundingDINO.groundingdino.util.inference import load_model, predict, annotate\n",
        "import GroundingDINO.groundingdino.datasets.transforms as T"
      ],
      "metadata": {
        "id": "EeN7uSDWLKYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def read_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    clases = []\n",
        "    lista = os.listdir(folder_path)\n",
        "\n",
        "    for lis in lista:\n",
        "        img_path = os.path.join(folder_path, lis)\n",
        "        img = cv2.imread(img_path)\n",
        "        images.append(img)\n",
        "        clases.append(os.path.splitext(lis)[0])\n",
        "\n",
        "    return images, clases\n",
        "\n",
        "def save_results(image, boxes, class_id, out_folder):\n",
        "    # Norm\n",
        "    xc, yc, an, al = boxes[0][0], boxes[0][1], boxes[0][2], boxes[0][3]\n",
        "\n",
        "    xc, yc, an, al = max(0, min(1, xc)), max(0, min(1, yc)), max(0, min(1, an)), max(0, min(1, al))\n",
        "\n",
        "    list_info = [f\"{class_id} {xc} {yc} {an} {al}\"]\n",
        "\n",
        "    time_now = str(time()).replace('.', '')\n",
        "\n",
        "    cv2.imwrite(f\"{out_folder}/{time_now}.jpg\", image)\n",
        "\n",
        "    for info in list_info:\n",
        "        with open(f\"{out_folder}/{time_now}.txt\", 'a') as f:\n",
        "            f.write(info)\n",
        "\n",
        "def main():\n",
        "    img_folder_path = '/content/data/images'\n",
        "    out_folder_path = '/content/data/annotations'\n",
        "    class_id = 0\n",
        "    save_results_flag = True\n",
        "\n",
        "    images, classes = read_images_from_folder(img_folder_path)\n",
        "    num_images = len(images)\n",
        "\n",
        "    print(f\"Imagenes: {num_images}\")\n",
        "    print(f'Nombres: {classes}')\n",
        "\n",
        "    home = os.getcwd()\n",
        "\n",
        "    # Config Path\n",
        "    config_path = os.path.join(home, \"/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
        "\n",
        "    # CheckPoint Weights\n",
        "    check_point_path = '/content/weights/groundingdino_swint_ogc.pth'\n",
        "\n",
        "    # Model\n",
        "    model = load_model(config_path, check_point_path)\n",
        "\n",
        "    # Prompt\n",
        "    text_prompt = 'bill bank'\n",
        "    box_threshold = 0.45\n",
        "    text_threshold = 0.25\n",
        "\n",
        "    for con in range(num_images):\n",
        "        img = images[con]\n",
        "        print(\"------------------//--------------------\")\n",
        "        print(f\"Image: {classes[con]}\")\n",
        "\n",
        "        img_copy = img.copy()\n",
        "\n",
        "        transform = T.Compose([\n",
        "            T.RandomResize([800], max_size=1333),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        img_source = Image.fromarray(img).convert(\"RGB\")\n",
        "        img_transform, _ = transform(img_source, None)\n",
        "\n",
        "        boxes, logits, phrases = predict(\n",
        "            model=model,\n",
        "            image=img_transform,\n",
        "            caption=text_prompt,\n",
        "            box_threshold=box_threshold,\n",
        "            text_threshold=text_threshold,\n",
        "            device=DEVICE)\n",
        "\n",
        "        if len(boxes) != 0:\n",
        "            if save_results_flag:\n",
        "                save_results(img_copy, boxes, class_id, out_folder_path)\n",
        "\n",
        "        annotated_img = annotate(image_source=img, boxes=boxes, logits=logits, phrases=phrases)\n",
        "        out_frame = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "1lHB5k4qIyre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compress annotations"
      ],
      "metadata": {
        "id": "uqwG5goqL8v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/content/data/annotations.zip\" \"/content/data/annotations\""
      ],
      "metadata": {
        "id": "d1QTVlclMBRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete old images"
      ],
      "metadata": {
        "id": "MFXLZTqIMZle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import rmtree\n",
        "rmtree(\"/content/data/annotations\")"
      ],
      "metadata": {
        "id": "9vrxn7bQMbHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Yolo v8 Model"
      ],
      "metadata": {
        "id": "Cgj-DO0GPjiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "oiNrZgwtP9LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model"
      ],
      "metadata": {
        "id": "7f9AmfeLQdfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/models"
      ],
      "metadata": {
        "id": "syXVsZf1QxsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt"
      ],
      "metadata": {
        "id": "z6HfH_7xQftF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train custom model"
      ],
      "metadata": {
        "id": "TJw-h6e5SgKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "id": "GWFuTwZ0T7gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0a1b4e-b6ef-41eb-d202-4040fec284c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Model\n",
        "model = YOLO('/content/models/yolov8n.pt')\n",
        "\n",
        "def main():\n",
        "    #Train\n",
        "    model.train(data='/content/dataTrain/data.yaml', epochs = 30, batch = 64, imgsz = 640, device = 'cuda')\n",
        "\n",
        "if __name__ == 'main':\n",
        "    main()"
      ],
      "metadata": {
        "id": "I2LBw6d6UXTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}